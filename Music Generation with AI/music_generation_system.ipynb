{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZTpCmt8xLNN"
      },
      "source": [
        "Music Generation System"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-5pREnvxLNP"
      },
      "source": [
        "Import essential libraries for data processing, model building, and MIDI file handling.\n",
        "\n",
        "numpy: For numerical computations.\n",
        "\n",
        "tensorflow/keras: For deep learning model creation.\n",
        "\n",
        "music21: For parsing and processing MIDI files.\n",
        "\n",
        "os: To work with file paths.\n",
        "\n",
        "tqdm: To display progress bars."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lFMEP2mIxLNP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from music21 import note, chord, stream, converter, instrument\n",
        "import os\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slnmNKV4xLNQ"
      },
      "source": [
        "Encapsulates all functionalities for training, generating, and saving a music model.\n",
        "\n",
        "\n",
        "prepare_sequences: Converts notes to numerical sequences for model input/output.\n",
        "\n",
        "create_model: Builds an LSTM-based model for music generation.\n",
        "\n",
        "train: Prepares data from MIDI files and trains the model.\n",
        "\n",
        "save_model: Saves the trained model to a file.\n",
        "\n",
        "generate_music: Produces a sequence of notes from a starting pattern.\n",
        "\n",
        "create_midi: Converts the generated notes back into a MIDI file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EzlqHFUpxLNR"
      },
      "outputs": [],
      "source": [
        "class MusicGenerator:\n",
        "    def __init__(self, sequence_length=100):\n",
        "        self.sequence_length = sequence_length\n",
        "        self.notes = []\n",
        "        self.note_to_int = {}\n",
        "        self.int_to_note = {}\n",
        "        self.model = None\n",
        "\n",
        "    def prepare_sequences(self, notes):\n",
        "        unique_notes = sorted(set(notes))\n",
        "        self.note_to_int = dict((note, number) for number, note in enumerate(unique_notes))\n",
        "        self.int_to_note = dict((number, note) for number, note in enumerate(unique_notes))\n",
        "\n",
        "        network_input = []\n",
        "        network_output = []\n",
        "\n",
        "        for i in range(0, len(notes) - self.sequence_length, 1):\n",
        "            sequence_in = notes[i:i + self.sequence_length]\n",
        "            sequence_out = notes[i + self.sequence_length]\n",
        "            network_input.append([self.note_to_int[char] for char in sequence_in])\n",
        "            network_output.append(self.note_to_int[sequence_out])\n",
        "\n",
        "        n_patterns = len(network_input)\n",
        "        n_vocab = len(unique_notes)\n",
        "\n",
        "        network_input = np.reshape(network_input, (n_patterns, self.sequence_length, 1))\n",
        "        network_input = network_input / float(n_vocab)\n",
        "\n",
        "        network_output = tf.keras.utils.to_categorical(network_output)\n",
        "\n",
        "        return network_input, network_output, n_vocab\n",
        "\n",
        "    def create_model(self, n_vocab):\n",
        "        model = models.Sequential()\n",
        "\n",
        "        model.add(layers.LSTM(256, input_shape=(self.sequence_length, 1), return_sequences=True))\n",
        "        model.add(layers.Dropout(0.3))\n",
        "\n",
        "        model.add(layers.LSTM(512, return_sequences=True))\n",
        "        model.add(layers.Dropout(0.3))\n",
        "\n",
        "        model.add(layers.LSTM(256))\n",
        "        model.add(layers.Dropout(0.3))\n",
        "\n",
        "        model.add(layers.Dense(256))\n",
        "        model.add(layers.Dropout(0.3))\n",
        "\n",
        "        model.add(layers.Dense(n_vocab, activation='softmax'))\n",
        "\n",
        "        model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "        self.model = model\n",
        "        return model\n",
        "\n",
        "    def train(self, midi_files_path, epochs=50, batch_size=64):\n",
        "        for file in os.listdir(midi_files_path):\n",
        "            if file.endswith(('.mid', '.midi')):\n",
        "                try:\n",
        "                    midi_path = os.path.join(midi_files_path, file)\n",
        "                    midi = converter.parse(midi_path)\n",
        "                    notes_to_parse = None\n",
        "\n",
        "                    try:\n",
        "                        s2 = instrument.partitionByInstrument(midi)\n",
        "                        notes_to_parse = s2.parts[0].recurse()\n",
        "                    except:\n",
        "                        notes_to_parse = midi.flat.notes\n",
        "\n",
        "                    for element in notes_to_parse:\n",
        "                        if isinstance(element, note.Note):\n",
        "                            self.notes.append(str(element.pitch))\n",
        "                        elif isinstance(element, chord.Chord):\n",
        "                            self.notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {file}: {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "        if not self.notes:\n",
        "            raise ValueError(\"No valid MIDI files found or no notes extracted\")\n",
        "\n",
        "        # Prepare sequences\n",
        "        network_input, network_output, n_vocab = self.prepare_sequences(self.notes)\n",
        "\n",
        "        # Create and train model\n",
        "        model = self.create_model(n_vocab)\n",
        "        model.fit(network_input, network_output, epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "    def save_model(self):\n",
        "        self.model.save('model.h5')\n",
        "        print('Model saved to disk')\n",
        "\n",
        "    def generate_music(self, start_sequence, length=500):\n",
        "        pattern = start_sequence\n",
        "        prediction_output = []\n",
        "\n",
        "        for _ in tqdm(range(length), desc=\"Generating notes\"):\n",
        "            prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
        "            prediction_input = prediction_input / float(len(self.note_to_int))\n",
        "\n",
        "            prediction = self.model.predict(prediction_input, verbose=0)\n",
        "            idx = np.argmax(prediction)\n",
        "            result = self.int_to_note[idx]\n",
        "            prediction_output.append(result)\n",
        "\n",
        "            pattern = np.append(pattern[1:], idx)\n",
        "\n",
        "        return prediction_output\n",
        "\n",
        "    def create_midi(self, prediction_output, filename=\"generated_music.mid\"):\n",
        "        print(\"Creating MIDI file...\")\n",
        "        offset = 0\n",
        "        output_notes = []\n",
        "\n",
        "        for pattern in tqdm(prediction_output, desc=\"Converting to MIDI\"):\n",
        "            if ('.' in pattern) or pattern.isdigit():\n",
        "                notes_in_chord = pattern.split('.')\n",
        "                notes = []\n",
        "                for current_note in notes_in_chord:\n",
        "                    new_note = note.Note(int(current_note))\n",
        "                    new_note.storedInstrument = instrument.Piano()\n",
        "                    notes.append(new_note)\n",
        "                new_chord = chord.Chord(notes)\n",
        "                new_chord.offset = offset\n",
        "                output_notes.append(new_chord)\n",
        "            else:\n",
        "                new_note = note.Note(pattern)\n",
        "                new_note.offset = offset\n",
        "                new_note.storedInstrument = instrument.Piano()\n",
        "                output_notes.append(new_note)\n",
        "\n",
        "            offset += 0.5\n",
        "\n",
        "        midi_stream = stream.Stream(output_notes)\n",
        "        midi_stream.write('midi', fp=filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJmKXiOvxLNT"
      },
      "source": [
        "Creates an instance of the MusicGenerator class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "l3OrbtrVxLNT"
      },
      "outputs": [],
      "source": [
        "generator = MusicGenerator()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s28CTsuPxLNU"
      },
      "source": [
        "Trains the model using MIDI files stored in the midi_datasets directory. The training involves:\n",
        "Parsing MIDI files to extract notes/chords.\n",
        "Preparing sequences for the LSTM model.\n",
        "Training the LSTM-based model for note prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Low accuracy doesn't necessarily mean bad music - there are many valid next notes in a sequence.\n",
        "\n",
        "The model might generate pleasant music even with seemingly low accuracy scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuph2JnExLNU",
        "outputId": "f47941ea-d8b9-408d-fd16-1505c07a0742"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 44ms/step - accuracy: 0.0163 - loss: 5.4115\n",
            "Epoch 2/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 46ms/step - accuracy: 0.0198 - loss: 5.2512\n",
            "Epoch 3/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 46ms/step - accuracy: 0.0200 - loss: 5.2359\n",
            "Epoch 4/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 46ms/step - accuracy: 0.0219 - loss: 5.2238\n",
            "Epoch 5/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.0260 - loss: 5.1943\n",
            "Epoch 6/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.0282 - loss: 5.1670\n",
            "Epoch 7/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.0308 - loss: 5.1443\n",
            "Epoch 8/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 46ms/step - accuracy: 0.0359 - loss: 5.1085\n",
            "Epoch 9/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 46ms/step - accuracy: 0.0411 - loss: 5.0662\n",
            "Epoch 10/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.0439 - loss: 5.0277\n",
            "Epoch 11/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 46ms/step - accuracy: 0.0494 - loss: 4.9743\n",
            "Epoch 12/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.0566 - loss: 4.9111\n",
            "Epoch 13/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.0629 - loss: 4.8567\n",
            "Epoch 14/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.0679 - loss: 4.8037\n",
            "Epoch 15/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.0737 - loss: 4.7471\n",
            "Epoch 16/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.0783 - loss: 4.6971\n",
            "Epoch 17/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.0824 - loss: 4.6621\n",
            "Epoch 18/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 46ms/step - accuracy: 0.0874 - loss: 4.6059\n",
            "Epoch 19/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 46ms/step - accuracy: 0.0915 - loss: 4.5784\n",
            "Epoch 20/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.0949 - loss: 4.5407\n",
            "Epoch 21/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 47ms/step - accuracy: 0.1014 - loss: 4.4947\n",
            "Epoch 22/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.1047 - loss: 4.4750\n",
            "Epoch 23/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.1033 - loss: 4.4519\n",
            "Epoch 24/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 46ms/step - accuracy: 0.1101 - loss: 4.4190\n",
            "Epoch 25/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.1138 - loss: 4.4008\n",
            "Epoch 26/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.1160 - loss: 4.3683\n",
            "Epoch 27/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.1188 - loss: 4.3401\n",
            "Epoch 28/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 46ms/step - accuracy: 0.1216 - loss: 4.3305\n",
            "Epoch 29/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.1236 - loss: 4.3158\n",
            "Epoch 30/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.1270 - loss: 4.2840\n",
            "Epoch 31/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.1285 - loss: 4.2606\n",
            "Epoch 32/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.1314 - loss: 4.2558\n",
            "Epoch 33/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.1329 - loss: 4.2413\n",
            "Epoch 34/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 46ms/step - accuracy: 0.1325 - loss: 4.2241\n",
            "Epoch 35/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.1343 - loss: 4.2176\n",
            "Epoch 36/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.1341 - loss: 4.1986\n",
            "Epoch 37/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.1394 - loss: 4.1839\n",
            "Epoch 38/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 46ms/step - accuracy: 0.1426 - loss: 4.1614\n",
            "Epoch 39/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 46ms/step - accuracy: 0.1412 - loss: 4.1698\n",
            "Epoch 40/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.1399 - loss: 4.1667\n",
            "Epoch 41/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.1441 - loss: 4.1394\n",
            "Epoch 42/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.1431 - loss: 4.1339\n",
            "Epoch 43/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.1445 - loss: 4.1257\n",
            "Epoch 44/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.1479 - loss: 4.1287\n",
            "Epoch 45/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.1517 - loss: 4.0995\n",
            "Epoch 46/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.1505 - loss: 4.0943\n",
            "Epoch 47/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.1537 - loss: 4.0846\n",
            "Epoch 48/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.1534 - loss: 4.0832\n",
            "Epoch 49/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.1532 - loss: 4.0699\n",
            "Epoch 50/50\n",
            "\u001b[1m1548/1548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.1566 - loss: 4.0584\n"
          ]
        }
      ],
      "source": [
        "generator.train(\"midi_datasets\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVGAOD1rxLNV"
      },
      "source": [
        "Saves the trained model to a file (model.h5) for later use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TIWNI4gxLNV",
        "outputId": "093c7041-0a80-41f8-b736-f218a8f1cd8b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to disk\n"
          ]
        }
      ],
      "source": [
        "generator.save_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6_ijA9txLNV"
      },
      "source": [
        "Generates new music notes based on a starting sequence.\n",
        "\n",
        "start_sequence: Converts the first 100 notes of the dataset into numerical form.\n",
        "\n",
        "generate_music: Predicts the next sequence of notes based on the trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3u3SOySoxLNV",
        "outputId": "cef4311d-e953-48e3-b2d5-9b60f32db664"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating notes: 100%|██████████| 500/500 [00:34<00:00, 14.56it/s]\n"
          ]
        }
      ],
      "source": [
        "start_sequence = [generator.note_to_int[note] for note in generator.notes[:100]]\n",
        "generated_notes = generator.generate_music(start_sequence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocbyPRwAxLNV"
      },
      "source": [
        "Converts the generated notes into a MIDI file (generated_music.mid)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NooR_rDkxLNV",
        "outputId": "13a7da6c-eb36-43d4-9e4a-21a59faeba88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating MIDI file...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Converting to MIDI: 100%|██████████| 500/500 [00:00<00:00, 20499.82it/s]\n"
          ]
        }
      ],
      "source": [
        "generator.create_midi(generated_notes)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nullclass",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
